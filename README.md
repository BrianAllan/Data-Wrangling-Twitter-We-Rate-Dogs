## Wrangling and Analyzing Data from “We Rate Dogs” on Twitter

### Project Description

_Course_: **“Data Wrangling”** offered by Udacity as part of their **Data Analyst Nanodegree** Program.

_Data_: Tweet data from “We Rate Dogs” on Twitter along with a supplied image predictions file containing dog classification predictions for the images associated with each tweet ID.

_Project Tasks_:

- Gather data from three different kinds of sources (downloaded file, URL, and the Twitter API) in at least three different file formats (CSV, TSV, and TXT).
- In a [Jupyter notebook](https://brianallan.github.io/Data-Wrangling-Twitter-We-Rate-Dogs/), use `Python` to assess and clean the Twitter data using the “Define-Code-Test” framework, addressing at least 8 data quality issues and at least 2 tidiness issues, and saving the result as a cleaned and tidied master dataset.
- Analyze and visualize the data to produce at least three separate insights.
- Create a [data wrangling report](https://brianallan.github.io/Data-Wrangling-Twitter-We-Rate-Dogs/wrangle_report.html).
- Create an [activity report](https://brianallan.github.io/Data-Wrangling-Twitter-We-Rate-Dogs/act_report.html), summarizing the results of the analysis and supported by visualizations.



### Files Used

wrangle_act.ipynb

image-predictions.tsv (obtained from URL)    
tweet_json.txt (obtained from Twitter API)    
twitter-archive-enhanced.csv


### Tools Used

`Python` with `numpy`, `pandas`, `json`, `requests`, `time`, `tweepy`, `statsmodels`, and `matplotlib` in a Jupyter notebook with some code development using the Spyder IDE.